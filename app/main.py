
import os
import tempfile
import asyncio
import subprocess
from typing import Optional

from fastapi import FastAPI, Request, Response, HTTPException
from fastapi.responses import PlainTextResponse

from aiogram import Bot, Dispatcher, F, Router
from aiogram.types import Message, CallbackQuery, FSInputFile, Update
from aiogram.filters import CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.utils.keyboard import InlineKeyboardBuilder

from dotenv import load_dotenv

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN", "")
WEBHOOK_URL = os.getenv("WEBHOOK_URL", "")
SECRET_TOKEN = os.getenv("SECRET_TOKEN", "")
MAX_FILE_MB = int(os.getenv("MAX_FILE_MB", "18"))

if not BOT_TOKEN:
    raise RuntimeError("BOT_TOKEN is not set")

# aiogram 3.7+ way to set parse_mode
from aiogram.client.default import DefaultBotProperties

bot = Bot(BOT_TOKEN, default=DefaultBotProperties(parse_mode="HTML"))
dp = Dispatcher()
router = Router()
dp.include_router(router)

app = FastAPI()

# ---- Keyboards ----

def main_kb():
    kb = InlineKeyboardBuilder()
    kb.button(text="ðŸŽ§ ÐÑƒÐ´Ð¸Ð¾", callback_data="menu:audio")
    kb.button(text="ðŸŽ¦ Ð’Ð¸Ð´ÐµÐ¾ / ÐšÑ€ÑƒÐ¶Ð¾Ðº", callback_data="menu:video")
    kb.adjust(1)
    return kb.as_markup()

def audio_kb():
    kb = InlineKeyboardBuilder()
    kb.button(text="ðŸŽ¬â†’ðŸ”Š Ð˜Ð· Ð²Ð¸Ð´ÐµÐ¾", callback_data="audio:from_video")
    kb.button(text="â­•â†’ðŸ”Š Ð˜Ð· ÐºÑ€ÑƒÐ¶ÐºÐ°", callback_data="audio:from_circle")
    kb.button(text="ðŸ—£ï¸â†’ðŸ”Š Ð˜Ð· Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾", callback_data="audio:from_voice")
    kb.button(text="ðŸŽµâ†’ðŸ—£ï¸ ÐÑƒÐ´Ð¸Ð¾â†’Ð“Ð¾Ð»Ð¾Ñ", callback_data="audio:audio_to_voice")
    kb.button(text="ðŸŽ¬/â­•â†’ðŸ—£ï¸ Ð’Ð¸Ð´ÐµÐ¾/ÐšÑ€ÑƒÐ³â†’Ð“Ð¾Ð»Ð¾Ñ", callback_data="audio:media_to_voice")
    kb.button(text="â†©ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="menu:back")
    kb.adjust(1)
    return kb.as_markup()

def video_kb():
    kb = InlineKeyboardBuilder()
    kb.button(text="ðŸŽ¥âž¡ï¸â­• Ð’Ð¸Ð´ÐµÐ¾ â†’ ÐšÑ€ÑƒÐ¶Ð¾Ðº", callback_data="video:to_circle")
    kb.button(text="â­•âž¡ï¸ðŸŽ¥ ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ Ð’Ð¸Ð´ÐµÐ¾", callback_data="video:to_video")
    kb.button(text="â†©ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="menu:back")
    kb.adjust(1)
    return kb.as_markup()

# ---- State ----

class Flow(StatesGroup):
    waiting_input = State()  # store action name in state data: {"action": "video_to_circle"}

# ---- Helpers ----

def bytes_to_mb(n: int) -> float:
    return round(n / (1024 * 1024), 2)

async def run_ffmpeg(cmd: list):
    """Run ffmpeg command in thread executor; raise on non-zero return."""
    loop = asyncio.get_running_loop()
    def _run():
        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if proc.returncode != 0:
            raise RuntimeError(proc.stderr[-4000:])
        return proc
    return await loop.run_in_executor(None, _run)

async def tg_download_to_temp(file_id: str, suffix: str) -> str:
    f = await bot.get_file(file_id)
    # size validation if known
    size = getattr(f, "file_size", None)
    if size is not None and size > MAX_FILE_MB * 1024 * 1024:
        raise HTTPException(status_code=400, detail=f"Ð¤Ð°Ð¹Ð» ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹: {bytes_to_mb(size)} MB (Ð»Ð¸Ð¼Ð¸Ñ‚ {MAX_FILE_MB} MB)")
    fd, path = tempfile.mkstemp(suffix=suffix)
    os.close(fd)
    await bot.download(f, destination=path)
    return path

async def ff_video_to_circle(src: str) -> str:
    """Crop center square, scale to 240, no audio, h264 mp4 for video_note."""
    dst = src.rsplit(".", 1)[0] + "_circle.mp4"
    vf = "crop='min(iw,ih)':'min(iw,ih)',scale=240:240,fps=30"
    cmd = ["ffmpeg", "-y", "-i", src, "-vf", vf, "-an",
           "-c:v", "libx264", "-pix_fmt", "yuv420p", dst]
    await run_ffmpeg(cmd)
    return dst

async def ff_circle_to_video(src: str) -> str:
    dst = src.rsplit(".", 1)[0] + "_video.mp4"
    cmd = ["ffmpeg", "-y", "-i", src, "-c:v", "libx264", "-pix_fmt", "yuv420p", "-c:a", "aac", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst

async def ff_extract_audio(src: str) -> str:
    dst = src.rsplit(".", 1)[0] + ".mp3"
    cmd = ["ffmpeg", "-y", "-i", src, "-vn", "-acodec", "libmp3lame", "-ar", "48000", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst

async def ff_to_voice(src: str) -> str:
    """Any audio -> ogg/opus voice."""
    dst = src.rsplit(".", 1)[0] + ".ogg"
    cmd = ["ffmpeg", "-y", "-i", src, "-c:a", "libopus", "-b:a", "64k", "-vbr", "on", "-ac", "1", "-ar", "48000", dst]
    await run_ffmpeg(cmd)
    return dst

# ---- Handlers ----

@router.message(CommandStart())
async def on_start(message: Message, state: FSMContext):
    await state.clear()
    await message.answer("Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ:", reply_markup=main_kb())

@router.callback_query(F.data == "menu:audio")
async def cb_audio(c: CallbackQuery, state: FSMContext):
    await state.set_state(Flow.waiting_input)
    await state.update_data(action=None)  # clear
    await c.message.edit_text("ðŸŽ§ ÐÑƒÐ´Ð¸Ð¾: Ð²Ñ‹Ð±ÐµÑ€Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ", reply_markup=audio_kb())
    await c.answer()

@router.callback_query(F.data == "menu:video")
async def cb_video(c: CallbackQuery, state: FSMContext):
    await state.set_state(Flow.waiting_input)
    await state.update_data(action=None)
    await c.message.edit_text("ðŸŽ¦ Ð’Ð¸Ð´ÐµÐ¾ / ÐšÑ€ÑƒÐ¶Ð¾Ðº: Ð²Ñ‹Ð±ÐµÑ€Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ", reply_markup=video_kb())
    await c.answer()

@router.callback_query(F.data == "menu:back")
async def cb_back(c: CallbackQuery, state: FSMContext):
    await state.clear()
    await c.message.edit_text("Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ:", reply_markup=main_kb())
    await c.answer()

# Audio actions selection
@router.callback_query(F.data.startswith("audio:"))
async def select_audio(c: CallbackQuery, state: FSMContext):
    m = {
        "audio:from_video": "audio_from_video",
        "audio:from_circle": "audio_from_circle",
        "audio:from_voice": "audio_from_voice",
        "audio:audio_to_voice": "audio_to_voice",
        "audio:media_to_voice": "media_to_voice",
    }[c.data]
    await state.update_data(action=m)
    prompts = {
        "audio_from_video": "ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð²Ð¸Ð´ÐµÐ¾ ðŸŽ¬",
        "audio_from_circle": "ÐŸÑ€Ð¸ÑˆÐ»Ð¸ ÐºÑ€ÑƒÐ¶Ð¾Ðº â­•",
        "audio_from_voice": "ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ðŸ—£ï¸",
        "audio_to_voice": "ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð°ÑƒÐ´Ð¸Ð¾-Ñ„Ð°Ð¹Ð» ðŸŽµ (mp3/wav/ogg Ð¸ Ñ‚.Ð´.)",
        "media_to_voice": "ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð²Ð¸Ð´ÐµÐ¾ ðŸŽ¬ Ð¸Ð»Ð¸ ÐºÑ€ÑƒÐ¶Ð¾Ðº â­•",
    }
    await c.message.answer(prompts[m])
    await c.answer()

# Video actions selection
@router.callback_query(F.data.startswith("video:"))
async def select_video(c: CallbackQuery, state: FSMContext):
    m = {
        "video:to_circle": "video_to_circle",
        "video:to_video": "circle_to_video",
    }[c.data]
    await state.update_data(action=m)
    prompts = {
        "video_to_circle": "ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð²Ð¸Ð´ÐµÐ¾ ðŸŽ¥ â€” ÑÐ´ÐµÐ»Ð°ÑŽ ÐºÑ€ÑƒÐ¶Ð¾Ðº â­•",
        "circle_to_video": "ÐŸÑ€Ð¸ÑˆÐ»Ð¸ ÐºÑ€ÑƒÐ¶Ð¾Ðº â­• â€” ÑÐ´ÐµÐ»Ð°ÑŽ Ð²Ð¸Ð´ÐµÐ¾ ðŸŽ¥",
    }
    await c.message.answer(prompts[m])
    await c.answer()

# --- Content handlers (process according to action) ---

@router.message(F.video | F.video_note | F.voice | F.audio, Flow.waiting_input)
async def process_media(message: Message, state: FSMContext):
    data = await state.get_data()
    action = data.get("action")
    if not action:
        return

    try:
        if action == "video_to_circle" and message.video:
            src = await tg_download_to_temp(message.video.file_id, ".mp4")
            dst = await ff_video_to_circle(src)
            await message.answer_video_note(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        if action == "circle_to_video" and message.video_note:
            src = await tg_download_to_temp(message.video_note.file_id, ".mp4")
            dst = await ff_circle_to_video(src)
            await message.answer_video(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        if action == "audio_from_video" and message.video:
            src = await tg_download_to_temp(message.video.file_id, ".mp4")
            dst = await ff_extract_audio(src)
            await message.answer_audio(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        if action == "audio_from_circle" and message.video_note:
            src = await tg_download_to_temp(message.video_note.file_id, ".mp4")
            dst = await ff_extract_audio(src)
            await message.answer_audio(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        if action == "audio_from_voice" and message.voice:
            src = await tg_download_to_temp(message.voice.file_id, ".ogg")
            dst = await ff_extract_audio(src)
            await message.answer_audio(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        if action == "audio_to_voice" and message.audio:
            src = await tg_download_to_temp(message.audio.file_id, ".mp3")
            dst = await ff_to_voice(src)
            await message.answer_voice(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        if action == "media_to_voice" and (message.video or message.video_note):
            file_id = message.video.file_id if message.video else message.video_note.file_id
            suffix = ".mp4"
            src = await tg_download_to_temp(file_id, suffix)
            tmp_audio = await ff_extract_audio(src)
            dst = await ff_to_voice(tmp_audio)
            await message.answer_voice(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        # Fallback if wrong type
        await message.answer("Ð­Ñ‚Ð¾ Ð½Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ Ð´Ð»Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÑÐ½Ð¾Ð²Ð° ðŸ™Œ")

    except HTTPException as e:
        await message.answer(f"âš ï¸ {e.detail}")
    except Exception as e:
        await message.answer("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ„Ð°Ð¹Ð»Ð°.")
        # Optional: print to logs
        print("ERROR:", repr(e))

# ---- FastAPI part ----

@app.get("/", response_class=PlainTextResponse)
@app.head("/", response_class=PlainTextResponse)
async def health():
    return "ok"

@app.post("/")
async def webhook(request: Request):
    # Secret-token protection (optional)
    if SECRET_TOKEN:
        rtoken = request.headers.get("X-Telegram-Bot-Api-Secret-Token")
        if rtoken != SECRET_TOKEN:
            raise HTTPException(status_code=403, detail="Bad secret token")

    data = await request.json()
    # Parse dict -> Update object
    update = Update.model_validate(data)

    # Feed to aiogram
    await dp.feed_update(bot, update)
    return Response(status_code=200)

# ---- Startup: set webhook ----

@app.on_event("startup")
async def on_startup():
    if WEBHOOK_URL:
        await bot.set_webhook(url=WEBHOOK_URL, secret_token=(SECRET_TOKEN or None))
    else:
        print("WARNING: WEBHOOK_URL is not set; Telegram won't reach this app.")

@app.on_event("shutdown")
async def on_shutdown():
    await bot.session.close()
