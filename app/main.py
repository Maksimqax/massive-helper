
import os
import tempfile
import asyncio
import subprocess
from typing import Optional

from fastapi import FastAPI, Request, Response, HTTPException
from fastapi.responses import PlainTextResponse

from aiogram import Bot, Dispatcher, F, Router
from aiogram.types import Message, CallbackQuery, FSInputFile, Update, ReplyKeyboardMarkup, KeyboardButton, ReplyKeyboardRemove
from aiogram.filters import CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.utils.keyboard import InlineKeyboardBuilder
from aiogram.enums import ChatAction
from aiogram.exceptions import TelegramBadRequest

from dotenv import load_dotenv

load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN", "")
WEBHOOK_URL = os.getenv("WEBHOOK_URL", "")
SECRET_TOKEN = os.getenv("SECRET_TOKEN", "")
MAX_FILE_MB = int(os.getenv("MAX_FILE_MB", "18"))

if not BOT_TOKEN:
    raise RuntimeError("BOT_TOKEN is not set")

# aiogram 3.7+ way to set parse_mode
from aiogram.client.default import DefaultBotProperties

bot = Bot(BOT_TOKEN, default=DefaultBotProperties(parse_mode="HTML"))
dp = Dispatcher()
router = Router()
dp.include_router(router)

app = FastAPI()

# ---- Keyboards ----

def main_kb():
    kb = InlineKeyboardBuilder()
    kb.button(text="ðŸŽ§ ÐÑƒÐ´Ð¸Ð¾", callback_data="menu:audio")
    kb.button(text="ðŸŽ¦ Ð’Ð¸Ð´ÐµÐ¾/ÐšÑ€ÑƒÐ¶Ð¾Ðº", callback_data="menu:video")
    kb.adjust(1)
    return kb.as_markup()

def main_reply_kb():
    return ReplyKeyboardMarkup(
        resize_keyboard=True,
        keyboard=[
            [KeyboardButton(text="ðŸŽ¦ Ð’Ð¸Ð´ÐµÐ¾/ÐšÑ€ÑƒÐ¶Ð¾Ðº"), KeyboardButton(text="ðŸŽ§ ÐÑƒÐ´Ð¸Ð¾")],
            
        ]
    )

def video_reply_kb():
    return ReplyKeyboardMarkup(
        resize_keyboard=True,
        keyboard=[
            [KeyboardButton(text="ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾ â†’ â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº")],
            [KeyboardButton(text="â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾")],
            [KeyboardButton(text="â¬… ÐÐ°Ð·Ð°Ð´")]
        ]
    )

def audio_reply_kb():
    return ReplyKeyboardMarkup(
        resize_keyboard=True,
        keyboard=[
            [KeyboardButton(text="ðŸŽ¬ Ð’Ð¸Ð´ÐµÐ¾ â†’ ðŸ”Š ÐÑƒÐ´Ð¸Ð¾ (MP3)")],
            [KeyboardButton(text="â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ ðŸ”Š ÐÑƒÐ´Ð¸Ð¾ (MP3)")],
            [KeyboardButton(text="ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ â†’ ðŸ”Š ÐÑƒÐ´Ð¸Ð¾ (MP3)")],
            [KeyboardButton(text="ðŸŽµ ÐÑƒÐ´Ð¸Ð¾ â†’ ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ")],
            [KeyboardButton(text="ðŸŽ¬/â­• Ð’Ð¸Ð´ÐµÐ¾/ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ")],
            [KeyboardButton(text="â¬… ÐÐ°Ð·Ð°Ð´")]
        ]
    )

    kb = InlineKeyboardBuilder()
    kb.button(text="ðŸŽ§ ÐÑƒÐ´Ð¸Ð¾", callback_data="menu:audio")
    kb.button(text="ðŸŽ¦ Ð’Ð¸Ð´ÐµÐ¾/ÐšÑ€ÑƒÐ¶Ð¾Ðº", callback_data="menu:video")
    kb.adjust(1)
    return kb.as_markup()

def audio_kb():
    kb = InlineKeyboardBuilder()
    kb.button(text="ðŸŽ¬ Ð’Ð¸Ð´ÐµÐ¾ â†’ ðŸ”Š ÐÑƒÐ´Ð¸Ð¾ (MP3)", callback_data="audio:from_video")
    kb.button(text="â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ ðŸ”Š ÐÑƒÐ´Ð¸Ð¾ (MP3)", callback_data="audio:from_circle")
    kb.button(text="ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ â†’ ðŸ”Š ÐÑƒÐ´Ð¸Ð¾ (MP3)", callback_data="audio:from_voice")
    kb.button(text="ðŸŽµ ÐÑƒÐ´Ð¸Ð¾ â†’ ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ", callback_data="audio:audio_to_voice")
    kb.button(text="ðŸŽ¬/â­• Ð’Ð¸Ð´ÐµÐ¾/ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ", callback_data="audio:media_to_voice")
    kb.button(text="â†©ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="menu:back")
    kb.adjust(1)
    return kb.as_markup()

def video_kb():
    kb = InlineKeyboardBuilder()
    kb.button(text="ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾ â†’ â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº", callback_data="video:to_circle")
    kb.button(text="â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾", callback_data="video:to_video")
    kb.button(text="â†©ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="menu:back")
    kb.adjust(1)
    return kb.as_markup()

# ---- State ----

class Flow(StatesGroup):
    waiting_input = State()  # store action name in state data: {"action": "video_to_circle"}

# ---- Helpers ----

def bytes_to_mb(n: int) -> float:
    return round(n / (1024 * 1024), 2)


async def _send_action_periodically(chat_id: int, action: ChatAction):
    """Send chat action every ~4s while long task runs."""
    try:
        while True:
            await bot.send_chat_action(chat_id, action=action)
            await asyncio.sleep(4)
    except asyncio.CancelledError:
        pass

async def run_ffmpeg(cmd: list):
    """Run ffmpeg command in thread executor; raise on non-zero return."""
    loop = asyncio.get_running_loop()
    def _run():
        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if proc.returncode != 0:
            raise RuntimeError(proc.stderr[-4000:])
        return proc
    return await loop.run_in_executor(None, _run)

async def tg_download_to_temp(file_id: str, suffix: str) -> str:
    f = await bot.get_file(file_id)
    # size validation if known
    size = getattr(f, "file_size", None)
    if size is not None and size > MAX_FILE_MB * 1024 * 1024:
        raise HTTPException(status_code=400, detail=f"Ð¤Ð°Ð¹Ð» ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹: {bytes_to_mb(size)} MB (Ð»Ð¸Ð¼Ð¸Ñ‚ {MAX_FILE_MB} MB)")
    fd, path = tempfile.mkstemp(suffix=suffix)
    os.close(fd)
    await bot.download(f, destination=path)
    return path



async def ff_extract_audio(src: str) -> str:
    """Extract audio track to mp3 from any media."""
    dst = src.rsplit(".", 1)[0] + ".mp3"
    cmd = ["ffmpeg", "-y", "-i", src, "-vn", "-acodec", "libmp3lame", "-ar", "48000", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst

async def ff_to_mp3(src: str) -> str:
    """Any audio (incl. ogg/opus) -> mp3 128k 48kHz."""
    dst = src.rsplit(".", 1)[0] + ".mp3"
    cmd = ["ffmpeg", "-y", "-i", src, "-vn", "-acodec", "libmp3lame", "-ar", "48000", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst

    """Crop to square for video_note and **preserve audio** (AAC)."""
    dst = src.rsplit(".", 1)[0] + "_circle.mp4"
    # 1:1 square, 480x480, keep audio (AAC), 30fps
    vf = "crop='min(iw,ih)':'min(iw,ih)',scale=480:480:flags=lanczos,fps=30,format=yuv420p"
    cmd = [
        "ffmpeg", "-y", "-i", src,
        "-vf", vf,
        "-c:v", "libx264", "-preset", "veryfast", "-profile:v", "baseline", "-level", "3.0",
        "-pix_fmt", "yuv420p",
        "-c:a", "aac", "-b:a", "128k", "-ac", "2", "-ar", "48000",
        "-movflags", "+faststart",
        dst
    ]
    await run_ffmpeg(cmd)
    return dst

async def ff_circle_to_video(src: str) -> str:
    dst = src.rsplit(".", 1)[0] + "_video.mp4"
    cmd = ["ffmpeg", "-y", "-i", src, "-c:v", "libx264", "-pix_fmt", "yuv420p", "-c:a", "aac", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst

async def ff_to_mp3(src: str) -> str:
    """Any audio (incl. ogg/opus) -> mp3 128k 48kHz."""
    dst = src.rsplit(".", 1)[0] + ".mp3"
    cmd = ["ffmpeg", "-y", "-i", src, "-vn", "-acodec", "libmp3lame", "-ar", "48000", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst

async def ff_to_mp3(src: str) -> str:
    """Any audio (incl. ogg/opus) -> mp3 128k 48kHz."""
    dst = src.rsplit(".", 1)[0] + ".mp3"
    cmd = ["ffmpeg", "-y", "-i", src, "-vn", "-acodec", "libmp3lame", "-ar", "48000", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst


    dst = src.rsplit(".", 1)[0] + ".mp3"
    cmd = ["ffmpeg", "-y", "-i", src, "-vn", "-acodec", "libmp3lame", "-ar", "48000", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst

async def ff_to_voice(src: str) -> str:
    """Any audio -> ogg/opus voice."""
    dst = src.rsplit(".", 1)[0] + ".ogg"
    cmd = ["ffmpeg", "-y", "-i", src, "-c:a", "libopus", "-b:a", "64k", "-vbr", "on", "-ac", "1", "-ar", "48000", dst]
    await run_ffmpeg(cmd)
    return dst


async def ff_video_to_circle(src: str) -> str:
    """Crop to square for video_note and preserve audio (AAC)."""
    dst = src.rsplit(".", 1)[0] + "_circle.mp4"
    vf = "crop='min(iw,ih)':'min(iw,ih)',scale=480:480:flags=lanczos,fps=30,format=yuv420p"
    cmd = [
        "ffmpeg", "-y", "-i", src,
        "-vf", vf,
        "-c:v", "libx264", "-preset", "veryfast", "-profile:v", "baseline", "-level", "3.0",
        "-pix_fmt", "yuv420p",
        "-c:a", "aac", "-b:a", "128k", "-ac", "2", "-ar", "48000",
        "-movflags", "+faststart",
        dst
    ]
    await run_ffmpeg(cmd)
    return dst

async def ff_extract_audio(src: str) -> str:
    """Extract audio track to mp3 from any media."""
    dst = src.rsplit(".", 1)[0] + ".mp3"
    cmd = ["ffmpeg", "-y", "-i", src, "-vn", "-acodec", "libmp3lame", "-ar", "48000", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst

async def ff_to_mp3(src: str) -> str:
    """Any audio (incl. ogg/opus) -> mp3 128k 48kHz."""
    dst = src.rsplit(".", 1)[0] + ".mp3"
    cmd = ["ffmpeg", "-y", "-i", src, "-vn", "-acodec", "libmp3lame", "-ar", "48000", "-b:a", "128k", dst]
    await run_ffmpeg(cmd)
    return dst

# ---- Handlers ----


@router.message(CommandStart())
async def on_start(message: Message, state: FSMContext):
    await state.clear()
    text = (
        "ðŸ‘‹ ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¡ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ÑÑ‚Ð¾Ð³Ð¾ Ð±Ð¾Ñ‚Ð° Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ñ€ÐµÐ²Ñ€Ð°Ñ‚Ð¸Ñ‚ÑŒ:\n"
        
        " ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾ Ð² â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº\n"
        
        " ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾ / ÐšÑ€ÑƒÐ¶Ð¾Ðº â­• Ð² ðŸ”Š ÐÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»\n"
        
        " ðŸŽµ ÐÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» Ð² ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ\n\n"
        
        "Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð½ÑƒÐ¶Ð½Ñ‹Ð¹ Ñ€Ð°Ð·Ð´ÐµÐ» Ð² Ð¼ÐµÐ½ÑŽ Ð½Ð¸Ð¶Ðµ:"
    )
    await message.answer(text, reply_markup=main_reply_kb())


@router.callback_query(F.data == "menu:audio")
async def cb_audio(c: CallbackQuery, state: FSMContext):
    await state.set_state(Flow.waiting_input)
    await state.update_data(action=None)  # clear
    try:
        await c.message.edit_text("ðŸŽ§ ÐÑƒÐ´Ð¸Ð¾: Ð²Ñ‹Ð±ÐµÑ€Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ", reply_markup=audio_kb())
    except TelegramBadRequest as e:
        if "message is not modified" in str(e):
            await c.answer("Ð’Ñ‹ ÑƒÐ¶Ðµ Ð² ÑÑ‚Ð¾Ð¼ Ð¼ÐµÐ½ÑŽ", show_alert=False)
        else:
            raise
    else:
        await c.answer()

@router.callback_query(F.data == "menu:video")
async def cb_video(c: CallbackQuery, state: FSMContext):
    await state.set_state(Flow.waiting_input)
    await state.update_data(action=None)
    try:
        await c.message.edit_text("ðŸŽ¦ Ð’Ð¸Ð´ÐµÐ¾ / ÐšÑ€ÑƒÐ¶Ð¾Ðº: Ð²Ñ‹Ð±ÐµÑ€Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ", reply_markup=video_kb())
    except TelegramBadRequest as e:
        if "message is not modified" in str(e):
            await c.answer("Ð’Ñ‹ ÑƒÐ¶Ðµ Ð² ÑÑ‚Ð¾Ð¼ Ð¼ÐµÐ½ÑŽ", show_alert=False)
        else:
            raise
    else:
        await c.answer()

@router.callback_query(F.data == "menu:back")
async def cb_back(c: CallbackQuery, state: FSMContext):
    await state.clear()
    try:
        await c.message.edit_text("Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ:", reply_markup=main_kb())
    except TelegramBadRequest as e:
        if "message is not modified" in str(e):
            await c.answer("Ð’Ñ‹ ÑƒÐ¶Ðµ Ð² ÑÑ‚Ð¾Ð¼ Ð¼ÐµÐ½ÑŽ", show_alert=False)
        else:
            raise
    else:
        await c.answer()

# Audio actions selection

@router.callback_query(F.data.startswith("audio:"))
async def select_audio(c: CallbackQuery, state: FSMContext):
    m = {
        "audio:from_video": "audio_from_video",
        "audio:from_circle": "audio_from_circle",
        "audio:from_voice": "audio_from_voice",
        "audio:audio_to_voice": "audio_to_voice",
        "audio:media_to_voice": "media_to_voice",
    }[c.data]
    await state.update_data(action=m)
    prompts = {
        "audio_from_video": "ðŸ”Š **Ð”Ð¾ÑÑ‚Ð°ÑŽ Ð·Ð²ÑƒÐº Ð¸Ð· Ð²Ð¸Ð´ÐµÐ¾**\nÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð²Ð¸Ð´ÐµÐ¾ ðŸŽ¬ â€” Ð²ÐµÑ€Ð½Ñƒ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ (mp3).",
        "audio_from_circle": "ðŸ”Š **Ð”Ð¾ÑÑ‚Ð°ÑŽ Ð·Ð²ÑƒÐº Ð¸Ð· ÐºÑ€ÑƒÐ¶ÐºÐ°**\nÐŸÑ€Ð¸ÑˆÐ»Ð¸ ÐºÑ€ÑƒÐ¶Ð¾Ðº â­• â€” Ð²ÐµÑ€Ð½Ñƒ Ð°ÑƒÐ´Ð¸Ð¾ (mp3).",
        "audio_from_voice": "ðŸ”Š **Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ â†’ Ð°ÑƒÐ´Ð¸Ð¾**\nÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ðŸ—£ï¸ â€” Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÑŽ Ð² .ogg/.mp3.",
        "audio_to_voice": "ðŸ—£ï¸ **ÐÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» â†’ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ**\nÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» (mp3/wav/ogg) â€” ÑÐ´ÐµÐ»Ð°ÑŽ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ (ogg/opus).",
        "media_to_voice": "ðŸ—£ï¸ **Ð’Ð¸Ð´ÐµÐ¾/ÐºÑ€ÑƒÐ¶Ð¾Ðº â†’ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ**\nÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð²Ð¸Ð´ÐµÐ¾ ðŸŽ¬ Ð¸Ð»Ð¸ ÐºÑ€ÑƒÐ¶Ð¾Ðº â­• â€” ÑÐ´ÐµÐ»Ð°ÑŽ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ (ogg/opus).",
    }
    await state.set_state(Flow.waiting_input)
    try:
        await c.message.edit_text(prompts[m], reply_markup=audio_kb(), parse_mode="Markdown")
    except TelegramBadRequest as e:
        if "message is not modified" in str(e):
            await c.answer("Ð’Ñ‹ ÑƒÐ¶Ðµ Ð² ÑÑ‚Ð¾Ð¼ Ð¼ÐµÐ½ÑŽ", show_alert=False)
        else:
            raise
    else:
        await c.answer()


# Video actions selection

@router.callback_query(F.data.startswith("video:"))
async def select_video(c: CallbackQuery, state: FSMContext):
    m = {
        "video:to_circle": "video_to_circle",
        "video:to_video": "circle_to_video",
    }[c.data]
    await state.update_data(action=m)
    prompts = {
        "video_to_circle": "â­• **Ð’Ð¸Ð´ÐµÐ¾ â†’ ÐšÑ€ÑƒÐ¶Ð¾Ðº**\nÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾ ðŸŽ¥ â€” Ñ ÑÐ´ÐµÐ»Ð°ÑŽ Ð¸Ð· Ð½ÐµÐ³Ð¾ ÐºÑ€ÑƒÐ¶Ð¾Ðº. Ð’Ð¸Ð´ÐµÐ¾ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð½Ðµ Ð´Ð¾Ð»ÑŒÑˆÐµ ~60 ÑÐµÐº Ð¸ Ð½Ðµ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð»Ð¸Ð¼Ð¸Ñ‚Ð° Ñ„Ð°Ð¹Ð»Ð°.\n\nÐ“Ð¾Ñ‚Ð¾Ð²? ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐ¹ Ñ„Ð°Ð¹Ð».",
        "circle_to_video": "ðŸŽ¥ **ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ Ð’Ð¸Ð´ÐµÐ¾**\nÐŸÑ€Ð¸ÑˆÐ»Ð¸ ÐºÑ€ÑƒÐ¶Ð¾Ðº â­• â€” Ð²ÐµÑ€Ð½Ñƒ ÐµÐ³Ð¾ Ð² Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð²Ð¸Ð´ÐµÐ¾Ñ„Ð°Ð¹Ð» Ñ ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¾Ð¹.\n\nÐ“Ð¾Ñ‚Ð¾Ð²? ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐ¹ Ñ„Ð°Ð¹Ð».",
    }
    try:
        await c.message.edit_text(prompts[m], reply_markup=video_kb(), parse_mode="Markdown")
    except TelegramBadRequest as e:
        if "message is not modified" in str(e):
            await c.answer("Ð’Ñ‹ ÑƒÐ¶Ðµ Ð² ÑÑ‚Ð¾Ð¼ Ð¼ÐµÐ½ÑŽ", show_alert=False)
        else:
            raise
    else:
        await c.answer()



# ---- Reply Keyboard handlers ----

@router.message(F.text == "ðŸŽ¦ Ð’Ð¸Ð´ÐµÐ¾/ÐšÑ€ÑƒÐ¶Ð¾Ðº")
async def on_text_menu_video(message: Message, state: FSMContext):
    await state.set_state(Flow.waiting_input)
    await state.update_data(action=None)
    await message.answer("ðŸŽ¦ Ð’Ð¸Ð´ÐµÐ¾ / ÐšÑ€ÑƒÐ¶Ð¾Ðº: Ð²Ñ‹Ð±ÐµÑ€Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ð½Ð° ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ðµ â¤µï¸", reply_markup=video_reply_kb())

@router.message(F.text == "ðŸŽ§ ÐÑƒÐ´Ð¸Ð¾")
async def on_text_menu_audio(message: Message, state: FSMContext):
    await state.set_state(Flow.waiting_input)
    await state.update_data(action=None)
    await message.answer("ðŸŽ§ ÐÑƒÐ´Ð¸Ð¾: Ð²Ñ‹Ð±ÐµÑ€Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ð½Ð° ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ðµ â¤µï¸", reply_markup=audio_reply_kb())

@router.message(F.text == "â¬… ÐÐ°Ð·Ð°Ð´")
async def on_text_back(message: Message, state: FSMContext):
    await state.clear()
    await message.answer("Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ:", reply_markup=main_reply_kb())

# Functions (reply keyboard)
@router.message(F.text == "ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾ â†’ â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº")
async def on_text_v_to_circle(message: Message, state: FSMContext):
    await state.update_data(action="video_to_circle")
    await message.answer("ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð²Ð¸Ð´ÐµÐ¾ ðŸŽ¥ â€” ÑÐ´ÐµÐ»Ð°ÑŽ **ÐºÑ€ÑƒÐ¶Ð¾Ðº** â­•.", reply_markup=video_reply_kb())

@router.message(F.text == "â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾")
async def on_text_circle_to_v(message: Message, state: FSMContext):
    await state.update_data(action="circle_to_video")
    await message.answer("ÐŸÑ€Ð¸ÑˆÐ»Ð¸ ÐºÑ€ÑƒÐ¶Ð¾Ðº â­• â€” Ð²ÐµÑ€Ð½Ñƒ Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ðµ **Ð²Ð¸Ð´ÐµÐ¾** ðŸŽ¥.", reply_markup=video_reply_kb())

@router.message(F.text == "ðŸŽ¬ Ð’Ð¸Ð´ÐµÐ¾ â†’ ðŸ”Š ÐÑƒÐ´Ð¸Ð¾ (MP3)")
async def on_text_a_from_video(message: Message, state: FSMContext):
    await state.update_data(action="audio_from_video")
    await message.answer("ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð²Ð¸Ð´ÐµÐ¾ ðŸŽ¬ â€” Ð´Ð¾ÑÑ‚Ð°Ð½Ñƒ **Ð°ÑƒÐ´Ð¸Ð¾ (MP3)** ðŸ”Š.", reply_markup=audio_reply_kb())

@router.message(F.text == "â­• ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ ðŸ”Š ÐÑƒÐ´Ð¸Ð¾ (MP3)")
async def on_text_a_from_circle(message: Message, state: FSMContext):
    await state.update_data(action="audio_from_circle")
    await message.answer("ÐŸÑ€Ð¸ÑˆÐ»Ð¸ ÐºÑ€ÑƒÐ¶Ð¾Ðº â­• â€” Ð´Ð¾ÑÑ‚Ð°Ð½Ñƒ **Ð°ÑƒÐ´Ð¸Ð¾ (MP3)** ðŸ”Š.", reply_markup=audio_reply_kb())

@router.message(F.text == "ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ â†’ ðŸ”Š ÐÑƒÐ´Ð¸Ð¾ (MP3)")
async def on_text_a_from_voice(message: Message, state: FSMContext):
    await state.update_data(action="audio_from_voice")
    await message.answer("ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ðŸ—£ï¸ â€” ÑÐ´ÐµÐ»Ð°ÑŽ **Ð°ÑƒÐ´Ð¸Ð¾ (MP3)** ðŸ”Š.", reply_markup=audio_reply_kb())

@router.message(F.text == "ðŸŽµ ÐÑƒÐ´Ð¸Ð¾ â†’ ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ")
async def on_text_audio_to_voice(message: Message, state: FSMContext):
    await state.update_data(action="audio_to_voice")
    await message.answer("ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð» ðŸŽµ â€” Ð²ÐµÑ€Ð½Ñƒ **Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ** ðŸ—£ï¸ (ogg/opus).", reply_markup=audio_reply_kb())

@router.message(F.text == "ðŸŽ¬/â­• Ð’Ð¸Ð´ÐµÐ¾/ÐšÑ€ÑƒÐ¶Ð¾Ðº â†’ ðŸ—£ï¸ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ")
async def on_text_media_to_voice(message: Message, state: FSMContext):
    await state.update_data(action="media_to_voice")
    await message.answer("ÐŸÑ€Ð¸ÑˆÐ»Ð¸ **Ð²Ð¸Ð´ÐµÐ¾** ðŸŽ¬ Ð¸Ð»Ð¸ **ÐºÑ€ÑƒÐ¶Ð¾Ðº** â­• â€” ÑÐ´ÐµÐ»Ð°ÑŽ **Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ** ðŸ—£ï¸.", reply_markup=audio_reply_kb())

# --- Content handlers (process according to action) ---


@router.message(F.video | F.video_note | F.voice | F.audio, Flow.waiting_input)
async def process_media(message: Message, state: FSMContext):
    data = await state.get_data()
    action = data.get("action")
    if not action:
        return

    async def action_loop(act: ChatAction):
        task = asyncio.create_task(_send_action_periodically(message.chat.id, act))
        return task

    try:
        # VIDEO -> CIRCLE (video note)
        if action == "video_to_circle" and message.video:
            act = await action_loop(ChatAction.RECORD_VIDEO_NOTE)
            try:
                src = await tg_download_to_temp(message.video.file_id, ".mp4")
                dst = await ff_video_to_circle(src)
            finally:
                act.cancel()
            await bot.send_chat_action(message.chat.id, action=ChatAction.UPLOAD_VIDEO_NOTE)
            await message.answer_video_note(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        # CIRCLE -> VIDEO
        if action == "circle_to_video" and message.video_note:
            act = await action_loop(ChatAction.RECORD_VIDEO)
            try:
                src = await tg_download_to_temp(message.video_note.file_id, ".mp4")
                dst = await ff_circle_to_video(src)
            finally:
                act.cancel()
            await bot.send_chat_action(message.chat.id, action=ChatAction.UPLOAD_VIDEO)
            await message.answer_video(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        # AUDIO FROM VIDEO
        if action == "audio_from_video" and message.video:
            act = await action_loop(ChatAction.RECORD_VOICE)
            try:
                src = await tg_download_to_temp(message.video.file_id, ".mp4")
                dst = await ff_extract_audio(src)
            finally:
                act.cancel()
            await bot.send_chat_action(message.chat.id, action=ChatAction.UPLOAD_DOCUMENT)
            await message.answer_audio(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        # AUDIO FROM CIRCLE
        if action == "audio_from_circle" and message.video_note:
            act = await action_loop(ChatAction.RECORD_VOICE)
            try:
                src = await tg_download_to_temp(message.video_note.file_id, ".mp4")
                dst = await ff_extract_audio(src)
            finally:
                act.cancel()
            await bot.send_chat_action(message.chat.id, action=ChatAction.UPLOAD_DOCUMENT)
            await message.answer_audio(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        # AUDIO FROM VOICE
        if action == "audio_from_voice" and message.voice:
            act = await action_loop(ChatAction.RECORD_VOICE)
            try:
                src = await tg_download_to_temp(message.voice.file_id, ".ogg")
                dst = await ff_to_mp3(src)
            finally:
                act.cancel()
            await bot.send_chat_action(message.chat.id, action=ChatAction.UPLOAD_DOCUMENT)
            await message.answer_audio(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        # AUDIOFILE -> VOICE
        if action == "audio_to_voice" and message.audio:
            act = await action_loop(ChatAction.RECORD_VOICE)
            try:
                file_id = message.audio.file_id
                suffix = ".mp3" if (message.audio.file_name or "").endswith(".mp3") else ".ogg"
                src = await tg_download_to_temp(file_id, suffix)
                dst = await ff_to_voice(src)
            finally:
                act.cancel()
            await bot.send_chat_action(message.chat.id, action=ChatAction.UPLOAD_VOICE)
            await message.answer_voice(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        # VIDEO/CIRCLE -> VOICE
        if action == "media_to_voice" and (message.video or message.video_note):
            act = await action_loop(ChatAction.RECORD_VOICE)
            try:
                if message.video:
                    file_id, suffix = message.video.file_id, ".mp4"
                else:
                    file_id, suffix = message.video_note.file_id, ".mp4"
                src = await tg_download_to_temp(file_id, suffix)
                tmp_audio = await ff_extract_audio(src)
                dst = await ff_to_voice(tmp_audio)
            finally:
                act.cancel()
            await bot.send_chat_action(message.chat.id, action=ChatAction.UPLOAD_VOICE)
            await message.answer_voice(FSInputFile(dst))
            await message.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ âœ…")
            return

        # Fallback if wrong type
        await message.answer("Ð­Ñ‚Ð¾ Ð½Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚ Ð´Ð»Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÑÐ½Ð¾Ð²Ð° ðŸ™Œ")

    except HTTPException as e:
        await message.answer(f"âš ï¸ {e.detail}")
    except Exception as e:
        await message.answer("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ„Ð°Ð¹Ð»Ð°.")
        print("ERROR:", repr(e))

# ---- FastAPI part ----


@app.get("/", response_class=PlainTextResponse)
@app.head("/", response_class=PlainTextResponse)
async def health():
    return "ok"

@app.post("/")
async def webhook(request: Request):
    # Secret-token protection (optional)
    if SECRET_TOKEN:
        rtoken = request.headers.get("X-Telegram-Bot-Api-Secret-Token")
        if rtoken != SECRET_TOKEN:
            raise HTTPException(status_code=403, detail="Bad secret token")

    data = await request.json()
    # Parse dict -> Update object
    update = Update.model_validate(data)

    # Feed to aiogram
    await dp.feed_update(bot, update)
    return Response(status_code=200)

# ---- Startup: set webhook ----

@app.on_event("startup")
async def on_startup():
    if WEBHOOK_URL:
        await bot.set_webhook(url=WEBHOOK_URL, secret_token=(SECRET_TOKEN or None))
    else:
        print("WARNING: WEBHOOK_URL is not set; Telegram won't reach this app.")

@app.on_event("shutdown")
async def on_shutdown():
    await bot.session.close()